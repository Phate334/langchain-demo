{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReducedOpenAPISpec(servers=[{'url': 'http://localhost:8000'}], description='This is a price query service for a private hardware vendor, which returns a quotation based on the product model', endpoints=[('POST /cpu/price', 'Given a CPU model, return the price', {'description': 'Given a CPU model, return the price', 'responses': {'description': 'Successful Response', 'content': {'application/json': {'schema': {}}}}, 'requestBody': {'content': {'application/json': {'schema': {'properties': {'model': {'type': 'string', 'title': 'Model'}}, 'type': 'object', 'required': ['model'], 'title': 'Cpu'}}}, 'required': True}}), ('POST /gpu/price', 'Given a GPU model, return the price', {'description': 'Given a GPU model, return the price', 'responses': {'description': 'Successful Response', 'content': {'application/json': {'schema': {}}}}, 'requestBody': {'content': {'application/json': {'schema': {'properties': {'model': {'type': 'string', 'title': 'Model'}}, 'type': 'object', 'required': ['model'], 'title': 'Gpu'}}}, 'required': True}})])\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env', override=True)\n",
    "\n",
    "# https://python.langchain.com/docs/integrations/toolkits/openapi\n",
    "from langchain_community.chat_models.azure_openai import AzureChatOpenAI\n",
    "from langchain.agents.agent_toolkits.openapi import planner\n",
    "from langchain.agents.agent_toolkits.openapi.spec import reduce_openapi_spec\n",
    "from langchain.requests import RequestsWrapper\n",
    "import requests\n",
    "\n",
    "azure_llm = AzureChatOpenAI(azure_deployment=\"gpt-4\")\n",
    "requests_wrapper = RequestsWrapper()\n",
    "\n",
    "res = requests.get(\"http://localhost:8000/openapi.json\")\n",
    "price_api_spec = reduce_openapi_spec(res.json())\n",
    "print(price_api_spec)\n",
    "\n",
    "cpus = []\n",
    "with open('cpu.txt', encoding='utf-8') as f:\n",
    "    cpus = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_agent = planner.create_openapi_agent(price_api_spec, requests_wrapper, azure_llm)\n",
    "query = (f\"\"\"判斷以下這是甚麼類型的產品，然後用這個產品型號去相對應的API中搜尋價格。\n",
    "我想知道我的供應商是否有提供比以下這產品更便宜的價格:\n",
    "{cpus[-1]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: api_planner\n",
      "Action Input: I need to identify the product type for \"Intel i9-14900K\" and then find the corresponding API to search for its price to compare with the supplier's offering.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPlan:\n",
      "1. Based on the product name \"Intel i9-14900K\", we can evaluate that it is a CPU model.\n",
      "2. POST /cpu/price with the CPU model \"Intel i9-14900K\" as a parameter to get the price of the CPU for comparison with the supplier's offering.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe plan has been created, and now I need to execute the API calls.\n",
      "Action: api_controller\n",
      "Action Input: 1) POST /cpu/price with the CPU model \"Intel i9-14900K\" as a parameter to get the price of the CPU for comparison with the supplier's offering.\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to make a POST request to the \"/cpu/price\" endpoint with the CPU model as a parameter to get the price.\n",
      "\n",
      "Action: requests_post\n",
      "\n",
      "Action Input:\n",
      "```json\n",
      "{\n",
      "  \"url\": \"http://localhost:8000/cpu/price\",\n",
      "  \"data\": {\n",
      "    \"model\": \"Intel i9-14900K\"\n",
      "  },\n",
      "  \"output_instructions\": \"Extract the price information from the response.\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m20000\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: It seems like the output is a price, but I didn't follow the instructions properly for the output_instructions field. I need to make sure I follow the format exactly, including providing a proper output instruction.\n",
      "\n",
      "Action: requests_post\n",
      "\n",
      "Action Input:\n",
      "```json\n",
      "{\n",
      "  \"url\": \"http://localhost:8000/cpu/price\",\n",
      "  \"data\": {\n",
      "    \"model\": \"Intel i9-14900K\"\n",
      "  },\n",
      "  \"output_instructions\": \"Extract the full response.\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{\"price\":20000,\"model\":\"Intel i9-14900K\"}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I have successfully executed the POST request to the \"/cpu/price\" endpoint and received a response containing the price and model of the CPU. This information is what is needed to be returned to the user.\n",
      "\n",
      "Thought: I am finished executing the plan.\n",
      "\n",
      "Final Answer: The final output from executing the plan is the price and model of the CPU: {\"price\":20000,\"model\":\"Intel i9-14900K\"}.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe final output from executing the plan is the price and model of the CPU: {\"price\":20000,\"model\":\"Intel i9-14900K\"}.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI am finished executing a plan and have the information the user asked for.\n",
      "Final Answer: The price for the CPU model Intel i9-14900K from the API is $20,000, which is cheaper than the supplier's price of $20,700.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The price for the CPU model Intel i9-14900K from the API is $20,000, which is cheaper than the supplier's price of $20,700.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://smith.langchain.com/public/9707f4e4-ae2d-4aec-b363-4d00439ec641/r\n",
    "price_agent.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "ollama_api = \"https://ollama.phate.dev\"\n",
    "openchat_llm = Ollama(base_url=ollama_api, model=\"openchat-3.5-1210\")\n",
    "price_agent = planner.create_openapi_agent(price_api_spec, requests_wrapper, openchat_llm, agent_executor_kwargs={\"handle_parsing_errors\": True})\n",
    "query = (f\"\"\"判斷以下這是甚麼類型的產品，然後用這個產品型號去相對應的API中搜尋價格。\n",
    "我想知道我的供應商是否有提供比以下這產品更便宜的價格:\n",
    "{cpus[-1]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Action: api_planner\n",
      "Action Input: I need to find the right API calls to determine the product type, search for prices, and compare prices.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m 1. POST /cpu/price with the CPU model as a parameter to find the price of a specific CPU.\n",
      "2. POST /gpu/price with the GPU model as a parameter to find the price of a specific GPU.\n",
      "3. Compare the prices obtained from steps 1 and 2 to determine which product type has a lower price or better value.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I'm ready to execute the API calls.\n",
      "Action: api_controller\n",
      "Action Input: 1) POST /cpu/price with the CPU model as a parameter to find the price of a specific CPU.\n",
      "2) POST /gpu/price with the GPU model as a parameter to find the price of a specific GPU.\n",
      "3) Compare the prices obtained from steps 1 and 2 to determine which product type has a lower price or better value.\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to make two POST requests, one for each endpoint, to obtain the prices of the CPUs and GPUs. After that, I'll compare the prices to determine which product has a lower price or better value.\n",
      "\n",
      "Action: requests_post\n",
      "Action Input: {\n",
      "  \"url\": \"http://localhost:8000/cpu/price\",\n",
      "  \"data\": {\n",
      "    \"model\": \"Intel Core i9-10900K\"\n",
      "  },\n",
      "  \"output_instructions\": \"extract price\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m20000\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I have successfully made the first POST request and obtained the price of the CPU. Now, I'll make the second POST request to obtain the GPU price.\n",
      "\n",
      "Action: requests_post\n",
      "Action Input: {\n",
      "  \"url\": \"http://localhost:8000/gpu/price\",\n",
      "  \"data\": {\n",
      "    \"model\": \"NVIDIA GeForce RTX 3090\"\n",
      "  },\n",
      "  \"output_instructions\": \"extract price\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mModel not found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m It seems that the GPU model I provided is not recognized by the API, so I cannot obtain its price. I'll try another approach to resolve this issue.\n",
      "\n",
      "Action: requests_post\n",
      "Action Input: {\n",
      "  \"url\": \"http://localhost:8000/gpu/price\",\n",
      "  \"data\": {\n",
      "    \"model\": \"NVIDIA RTX 3080\"\n",
      "  },\n",
      "  \"output_instructions\": \"extract price\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mError: Model not found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m It appears that the API cannot recognize the provided GPU model. I will try another approach to obtain the prices of both CPU and GPU to make a comparison.\n",
      "\n",
      "Action: requests_post\n",
      "Action Input: {\n",
      "  \"url\": \"http://localhost:8000/cpu/price\",\n",
      "  \"data\": {\n",
      "    \"model\": \"Intel Core i9-11900K\"\n",
      "  },\n",
      "  \"output_instructions\": \"extract price\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m20,000\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I have successfully made the second POST request and obtained the price of the CPU. Now, I'll make another POST request to obtain the GPU price using a different model.\n",
      "\n",
      "Action: requests_post\n",
      "Action Input: {\n",
      "  \"url\": \"http://localhost:8000/gpu/price\",\n",
      "  \"data\": {\n",
      "    \"model\": \"NVIDIA RTX 3070\"\n",
      "  },\n",
      "  \"output_instructions\": \"extract price\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m价格未找到\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m It seems that the GPU model I provided is not recognized by the API, so I cannot obtain its price. I'll try another approach to resolve this issue.\n",
      "\n",
      "Action: requests_post\n",
      "Action Input: {\n",
      "  \"url\": \"http://localhost:8000/gpu/price\",\n",
      "  \"data\": {\n",
      "    \"model\": \"NVIDIA GeForce RTX 3060\"\n",
      "  },\n",
      "  \"output_instructions\": \"extract price\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mError: Model not found\u001b[0m\n",
      "Thought:"
     ]
    }
   ],
   "source": [
    "price_agent.run(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-demo-wAV8wxVh-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
